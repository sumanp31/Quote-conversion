{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from warnings import simplefilter\n",
    "\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Assignment3_TrainingSet.csv')\n",
    "test = pd.read_csv('Assignment3_TestSet.csv')\n",
    "\n",
    "## Data cleaning\n",
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "\n",
    "df_train['source'] = 'train'\n",
    "df_test['source'] = 'test'\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Coverage_info1', 'Coverage_info2', 'Coverage_info3', 'Field_info1',\n",
      "       'Field_info2', 'Field_info3', 'Field_info4', 'Geographic_info1',\n",
      "       'Geographic_info2', 'Geographic_info3', 'Geographic_info4',\n",
      "       'Geographic_info5', 'Original_Quote_Date', 'Personal_info1',\n",
      "       'Personal_info2', 'Personal_info3', 'Personal_info4', 'Personal_info5',\n",
      "       'Property_info1', 'Property_info2', 'Property_info3', 'Property_info4',\n",
      "       'Property_info5', 'QuoteConversion_Flag', 'Quote_ID', 'Sales_info1',\n",
      "       'Sales_info2', 'Sales_info3', 'Sales_info4', 'Sales_info5', 'source'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104301 entries, 0 to 104300\n",
      "Data columns (total 31 columns):\n",
      "Coverage_info1          104301 non-null int64\n",
      "Coverage_info2          104301 non-null int64\n",
      "Coverage_info3          104301 non-null object\n",
      "Field_info1             104301 non-null object\n",
      "Field_info2             104301 non-null float64\n",
      "Field_info3             104301 non-null object\n",
      "Field_info4             104301 non-null object\n",
      "Geographic_info1        104301 non-null int64\n",
      "Geographic_info2        104301 non-null int64\n",
      "Geographic_info3        104301 non-null int64\n",
      "Geographic_info4        104301 non-null object\n",
      "Geographic_info5        104301 non-null object\n",
      "Original_Quote_Date     104301 non-null object\n",
      "Personal_info1          104255 non-null object\n",
      "Personal_info2          104301 non-null int64\n",
      "Personal_info3          104301 non-null object\n",
      "Personal_info4          104301 non-null int64\n",
      "Personal_info5          54789 non-null float64\n",
      "Property_info1          104270 non-null object\n",
      "Property_info2          104301 non-null int64\n",
      "Property_info3          104301 non-null object\n",
      "Property_info4          104301 non-null int64\n",
      "Property_info5          104301 non-null int64\n",
      "QuoteConversion_Flag    78225 non-null float64\n",
      "Quote_ID                104301 non-null int64\n",
      "Sales_info1             104301 non-null int64\n",
      "Sales_info2             104301 non-null int64\n",
      "Sales_info3             104301 non-null int64\n",
      "Sales_info4             104301 non-null object\n",
      "Sales_info5             104301 non-null int64\n",
      "source                  104301 non-null object\n",
      "dtypes: float64(3), int64(15), object(13)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "print (cols)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coverage_info1\n",
      "[ 5  8  6 10 17 11  4 16 14 25  9 12  3 13  1  7  2 18 15 23 20 22 24 19\n",
      " -1 21]\n",
      "26\n",
      "\n",
      "Coverage_info2\n",
      "[22 25  2  1]\n",
      "4\n",
      "\n",
      "Coverage_info3\n",
      "['F' 'E' 'D' 'G' 'H' 'J' 'A' 'K' 'I' 'B' 'C' 'L']\n",
      "12\n",
      "\n",
      "Field_info1\n",
      "['J' 'F' 'B' 'K' 'C' 'E' 'D' 'A']\n",
      "8\n",
      "\n",
      "Field_info2\n",
      "[0.9691 1.0006 0.9153 0.8928 0.9566 0.8922 0.9838 0.887  0.9403 0.9497\n",
      " 0.893  0.9313 0.9919 0.9258 1.0101 0.9769 0.8793 0.9364 0.9392 0.9893\n",
      " 1.0005 0.9525 0.9023 0.9485 0.9219 0.8746 0.9368 0.9472 0.9487 0.9375\n",
      " 0.9223 0.9108 0.8945 0.9685 0.9482 0.9559 0.9194 0.9489]\n",
      "38\n",
      "\n",
      "Field_info3\n",
      "['1,165' '548' '935' '1,113' '965' '1,487' '564' '1,480']\n",
      "8\n",
      "\n",
      "Field_info4\n",
      "['N' 'Y']\n",
      "2\n",
      "\n",
      "Geographic_info1\n",
      "[ 3  4  2 12  1  9 14 15  5 13 11 24 25 10 23 17 20 22 18 19  8  6 21  7\n",
      " -1 16]\n",
      "26\n",
      "\n",
      "Geographic_info2\n",
      "[ 5 17  8 10  4 19  7 20 12  9  6 24 16 13 18 21 14 22 25 23 11 15 -1]\n",
      "23\n",
      "\n",
      "Geographic_info3\n",
      "[-1 25]\n",
      "2\n",
      "\n",
      "Geographic_info4\n",
      "['N' 'Y' ' ']\n",
      "3\n",
      "\n",
      "Geographic_info5\n",
      "['TX' 'NJ' 'CA' 'IL']\n",
      "4\n",
      "\n",
      "Original_Quote_Date\n",
      "['9/07/2013' '29/05/2014' '13/05/2015' '2/09/2014' '9/04/2015'\n",
      " '28/10/2014' '12/03/2014' '16/01/2014' '23/03/2014' '2/01/2014'\n",
      " '3/04/2014' '21/05/2014' '28/01/2015' '23/04/2013' '14/10/2013'\n",
      " '18/12/2014' '2/03/2015' '23/05/2013' '4/02/2014' '3/10/2013'\n",
      " '13/11/2014' '16/10/2013' '10/11/2014' '14/11/2014' '29/06/2013'\n",
      " '11/04/2013' '4/11/2013' '21/04/2015' '25/05/2014' '18/03/2013'\n",
      " '27/01/2015' '14/07/2014' '30/10/2014' '18/07/2013' '21/04/2014'\n",
      " '18/08/2014' '2/04/2015' '24/02/2015' '21/01/2015' '28/07/2014'\n",
      " '1/09/2014' '3/11/2014' '9/04/2013' '10/03/2014' '11/11/2014'\n",
      " '29/07/2014' '1/12/2014' '30/12/2014' '23/04/2015' '18/04/2015'\n",
      " '22/05/2014' '4/01/2014' '22/01/2015' '5/04/2013' '16/02/2013'\n",
      " '26/08/2013' '13/08/2014' '31/01/2014' '11/02/2015' '5/05/2014'\n",
      " '22/12/2014' '10/04/2015' '16/08/2014' '6/05/2015' '22/07/2014'\n",
      " '25/04/2015' '7/02/2013' '4/09/2014' '10/01/2014' '14/05/2015'\n",
      " '8/05/2013' '25/09/2013' '28/06/2013' '19/03/2015' '14/05/2013'\n",
      " '9/01/2013' '16/04/2015' '27/03/2015' '30/09/2013' '24/06/2013'\n",
      " '10/04/2013' '16/08/2013' '26/03/2014' '8/02/2013' '20/04/2015'\n",
      " '13/06/2013' '25/04/2013' '7/06/2014' '10/09/2013' '21/08/2014'\n",
      " '9/02/2015' '5/12/2013' '26/11/2014' '26/09/2014' '9/09/2014'\n",
      " '20/09/2014' '7/03/2014' '15/04/2014' '2/10/2014' '2/07/2014' '9/08/2013'\n",
      " '27/03/2013' '27/02/2014' '12/09/2014' '5/01/2013' '29/08/2013'\n",
      " '7/06/2013' '26/06/2014' '16/06/2014' '23/06/2013' '20/10/2014'\n",
      " '4/02/2015' '18/01/2013' '15/10/2013' '5/04/2014' '5/02/2014' '7/05/2014'\n",
      " '12/04/2013' '23/11/2013' '15/07/2014' '15/03/2013' '7/04/2015'\n",
      " '17/09/2013' '24/11/2013' '21/01/2014' '9/06/2014' '2/12/2014'\n",
      " '20/05/2013' '2/06/2014' '15/11/2014' '11/07/2014' '6/09/2014'\n",
      " '30/07/2013' '21/07/2013' '22/10/2014' '2/12/2013' '21/08/2013'\n",
      " '2/01/2013' '6/02/2013' '18/04/2014' '22/05/2013' '11/12/2013'\n",
      " '7/08/2014' '5/05/2015' '4/03/2015' '19/11/2014' '21/03/2014'\n",
      " '21/10/2013' '28/04/2014' '23/11/2014' '26/01/2013' '13/01/2014'\n",
      " '10/03/2015' '3/02/2014' '23/10/2013' '11/04/2014' '18/10/2013'\n",
      " '16/12/2014' '14/04/2015' '21/03/2015' '2/04/2014' '11/05/2014'\n",
      " '29/03/2014' '23/02/2015' '1/04/2013' '16/10/2014' '4/09/2013'\n",
      " '23/06/2014' '29/12/2014' '4/05/2015' '9/05/2014' '18/05/2015'\n",
      " '5/03/2013' '20/03/2014' '7/07/2014' '29/10/2013' '13/02/2013'\n",
      " '4/10/2013' '10/06/2014' '7/01/2014' '3/07/2014' '15/01/2015'\n",
      " '22/09/2014' '8/05/2014' '21/07/2014' '10/06/2013' '27/09/2013'\n",
      " '1/05/2014' '18/03/2014' '10/10/2014' '15/11/2013' '6/03/2014'\n",
      " '18/02/2014' '23/03/2015' '2/10/2013' '15/01/2014' '10/04/2014'\n",
      " '21/06/2013' '23/02/2014' '28/02/2013' '18/09/2014' '5/06/2014'\n",
      " '2/09/2013' '19/03/2014' '26/11/2013' '2/08/2013' '26/04/2014'\n",
      " '7/08/2013' '13/09/2013' '2/07/2013' '27/07/2013' '19/07/2013'\n",
      " '8/04/2014' '14/03/2015' '18/11/2014' '8/02/2015' '22/04/2015'\n",
      " '9/01/2014' '18/11/2013' '30/05/2013' '10/07/2014' '16/09/2014'\n",
      " '21/06/2014' '18/02/2013' '23/07/2014' '24/06/2014' '6/06/2013'\n",
      " '6/07/2013' '6/08/2014' '23/07/2013' '23/01/2015' '22/10/2013'\n",
      " '2/08/2014' '8/06/2013' '30/01/2015' '29/01/2014' '28/07/2013'\n",
      " '6/11/2014' '5/11/2014' '11/05/2013' '1/07/2013' '12/08/2013'\n",
      " '29/04/2015' '11/10/2013' '27/05/2013' '24/12/2014' '23/01/2013'\n",
      " '12/12/2014' '7/02/2014' '25/07/2013' '17/04/2015' '29/09/2014'\n",
      " '28/05/2013' '11/06/2013' '17/12/2014' '26/06/2013' '31/10/2014'\n",
      " '19/08/2013' '10/07/2013' '17/11/2014' '19/03/2013' '11/09/2013'\n",
      " '5/08/2014' '16/09/2013' '3/07/2013' '26/02/2014' '17/03/2015'\n",
      " '6/02/2014' '8/01/2015' '1/02/2013' '9/10/2013' '31/03/2014' '26/10/2014'\n",
      " '5/08/2013' '4/10/2014' '7/01/2015' '19/07/2014' '13/08/2013'\n",
      " '12/07/2013' '5/09/2013' '20/08/2014' '2/02/2015' '18/01/2015'\n",
      " '24/04/2013' '23/04/2014' '16/12/2013' '15/09/2014' '15/08/2013'\n",
      " '7/05/2013' '1/03/2015' '6/08/2013' '13/02/2014' '2/04/2013' '8/07/2013'\n",
      " '14/10/2014' '19/06/2014' '13/05/2013' '30/06/2014' '8/04/2015'\n",
      " '5/03/2014' '11/09/2014' '8/01/2014' '6/05/2013' '29/04/2014'\n",
      " '20/11/2013' '9/12/2013' '3/06/2013' '3/05/2013' '27/12/2013'\n",
      " '25/02/2014' '21/11/2014' '25/06/2014' '15/04/2015' '1/04/2015'\n",
      " '18/04/2013' '9/07/2014' '10/01/2013' '18/06/2014' '25/08/2014'\n",
      " '12/02/2015' '1/03/2013' '15/10/2014' '17/05/2015' '19/05/2014'\n",
      " '30/05/2014' '15/05/2013' '2/03/2014' '1/08/2013' '15/06/2013'\n",
      " '6/10/2014' '4/04/2015' '13/07/2014' '4/04/2014' '31/05/2013'\n",
      " '15/09/2013' '12/05/2014' '5/02/2013' '16/05/2013' '26/12/2013'\n",
      " '26/08/2014' '14/05/2014' '25/07/2014' '8/07/2014' '3/08/2013'\n",
      " '4/07/2013' '12/12/2013' '13/05/2014' '19/09/2014' '19/10/2013'\n",
      " '5/04/2015' '25/03/2013' '20/03/2015' '22/04/2013' '20/05/2014'\n",
      " '14/11/2013' '12/03/2015' '12/02/2014' '14/09/2013' '26/09/2013'\n",
      " '17/08/2014' '21/02/2014' '18/03/2015' '30/08/2013' '18/09/2013'\n",
      " '20/01/2015' '30/10/2013' '19/04/2014' '14/08/2014' '21/04/2013'\n",
      " '11/02/2014' '7/10/2014' '28/09/2014' '28/04/2015' '25/01/2014'\n",
      " '30/03/2014' '29/10/2014' '14/01/2013' '27/08/2014' '7/05/2015'\n",
      " '20/10/2013' '3/09/2013' '19/02/2013' '5/01/2015' '22/11/2013'\n",
      " '15/05/2015' '6/03/2015' '19/12/2013' '15/01/2013' '14/12/2014'\n",
      " '31/03/2015' '24/11/2014' '12/01/2015' '24/08/2013' '17/02/2015'\n",
      " '9/04/2014' '28/03/2013' '12/03/2013' '4/11/2014' '13/09/2014'\n",
      " '17/04/2014' '8/01/2013' '5/03/2015' '15/02/2013' '8/08/2013'\n",
      " '17/10/2014' '18/01/2014' '3/02/2015' '15/05/2014' '27/06/2013'\n",
      " '11/11/2013' '5/12/2014' '18/02/2015' '28/05/2014' '9/12/2014'\n",
      " '26/05/2014' '10/05/2015' '6/04/2014' '1/04/2014' '27/04/2014'\n",
      " '6/01/2013' '21/02/2013' '12/05/2015' '12/06/2014' '20/02/2013'\n",
      " '25/08/2013' '27/06/2014' '29/07/2013' '29/03/2015' '23/01/2014'\n",
      " '23/12/2014' '17/06/2014' '30/03/2015' '23/09/2014' '18/12/2013'\n",
      " '2/01/2015' '7/04/2014' '24/03/2014' '19/01/2015' '14/01/2015'\n",
      " '22/08/2014' '5/11/2013' '14/04/2014' '3/01/2014' '1/07/2014' '8/09/2014'\n",
      " '7/09/2014' '14/08/2013' '16/01/2013' '16/04/2013' '1/05/2015'\n",
      " '20/09/2013' '8/10/2013' '3/01/2013' '17/01/2014' '9/01/2015'\n",
      " '30/01/2014' '25/10/2013' '24/01/2015' '4/06/2014' '2/06/2013'\n",
      " '3/06/2014' '8/04/2013' '27/02/2015' '9/05/2013' '31/05/2014'\n",
      " '31/07/2013' '2/02/2013' '21/09/2013' '31/07/2014' '19/06/2013'\n",
      " '21/12/2014' '31/12/2013' '24/09/2014' '20/06/2013' '1/02/2015'\n",
      " '3/03/2015' '15/12/2014' '23/05/2014' '16/03/2015' '30/04/2014'\n",
      " '8/11/2014' '27/05/2014' '26/07/2014' '14/06/2013' '18/05/2013'\n",
      " '25/03/2015' '28/01/2014' '15/02/2014' '1/06/2013' '30/09/2014'\n",
      " '4/02/2013' '13/11/2013' '15/02/2015' '17/07/2013' '24/09/2013'\n",
      " '30/11/2013' '16/02/2015' '24/08/2014' '11/03/2013' '6/01/2014'\n",
      " '11/02/2013' '22/03/2015' '30/06/2013' '1/01/2015' '11/08/2013'\n",
      " '21/01/2013' '30/04/2013' '24/02/2014' '14/03/2013' '19/02/2014'\n",
      " '11/03/2014' '6/09/2013' '3/09/2014' '4/01/2015' '22/12/2013'\n",
      " '13/06/2014' '8/03/2014' '16/05/2014' '1/01/2014' '13/12/2013'\n",
      " '24/03/2013' '15/04/2013' '25/02/2015' '10/02/2015' '7/03/2013'\n",
      " '29/11/2014' '30/07/2014' '23/03/2013' '24/10/2013' '23/08/2014'\n",
      " '13/10/2014' '14/07/2013' '16/05/2015' '18/06/2013' '31/12/2014'\n",
      " '27/08/2013' '24/03/2015' '7/11/2013' '14/02/2013' '25/11/2013'\n",
      " '28/12/2013' '7/10/2013' '22/01/2013' '6/01/2015' '13/04/2015'\n",
      " '27/07/2014' '26/01/2015' '24/04/2014' '20/12/2014' '18/07/2014'\n",
      " '3/08/2014' '17/01/2013' '4/08/2013' '19/08/2014' '16/04/2014'\n",
      " '13/12/2014' '16/01/2015' '24/04/2015' '29/08/2014' '3/05/2015'\n",
      " '8/03/2015' '26/02/2015' '4/12/2014' '21/05/2013' '26/01/2014'\n",
      " '26/02/2013' '25/12/2014' '30/12/2013' '30/04/2015' '31/08/2014'\n",
      " '1/11/2013' '21/10/2014' '5/07/2013' '10/05/2014' '8/08/2014'\n",
      " '16/07/2014' '16/07/2013' '10/05/2013' '19/10/2014' '28/02/2014'\n",
      " '12/02/2013' '31/01/2013' '6/12/2013' '17/03/2014' '2/11/2013'\n",
      " '28/10/2013' '24/05/2013' '22/06/2013' '9/03/2015' '12/06/2013'\n",
      " '31/01/2015' '6/11/2013' '28/03/2014' '20/06/2014' '7/03/2015'\n",
      " '10/09/2014' '27/10/2014' '11/10/2014' '2/05/2014' '10/08/2013'\n",
      " '19/09/2013' '28/08/2013' '21/09/2014' '27/03/2014' '6/04/2015'\n",
      " '20/02/2014' '13/03/2015' '3/12/2013' '25/03/2014' '8/12/2014'\n",
      " '31/10/2013' '20/11/2014' '30/01/2013' '6/10/2013' '20/08/2013'\n",
      " '25/04/2014' '1/08/2014' '23/09/2013' '24/07/2013' '26/03/2015'\n",
      " '4/03/2014' '23/12/2013' '28/12/2014' '14/03/2014' '7/11/2014'\n",
      " '27/02/2013' '22/08/2013' '3/03/2014' '28/06/2014' '5/06/2013'\n",
      " '4/05/2013' '16/03/2014' '7/09/2013' '12/09/2013' '12/01/2014'\n",
      " '3/12/2014' '17/02/2014' '19/11/2013' '9/02/2013' '21/03/2013'\n",
      " '25/09/2014' '5/05/2013' '9/11/2014' '12/05/2013' '6/05/2014'\n",
      " '22/02/2013' '21/11/2013' '11/01/2014' '3/01/2015' '22/03/2013'\n",
      " '3/10/2014' '25/05/2013' '6/12/2014' '23/10/2014' '9/03/2013'\n",
      " '15/07/2013' '7/04/2013' '24/07/2014' '3/02/2013' '13/07/2013'\n",
      " '10/12/2013' '22/02/2015' '13/01/2015' '29/09/2013' '25/11/2014'\n",
      " '23/02/2013' '14/02/2014' '11/01/2013' '11/03/2015' '4/08/2014'\n",
      " '17/04/2013' '9/09/2013' '2/05/2015' '23/08/2013' '26/07/2013'\n",
      " '19/04/2015' '22/01/2014' '22/09/2013' '22/02/2014' '8/06/2014'\n",
      " '20/04/2014' '26/03/2013' '5/01/2014' '11/12/2014' '25/01/2015'\n",
      " '26/04/2013' '27/04/2015' '24/10/2014' '6/03/2013' '20/01/2014'\n",
      " '4/05/2014' '10/01/2015' '28/04/2013' '13/03/2014' '10/10/2013'\n",
      " '4/12/2013' '20/02/2015' '26/12/2014' '10/12/2014' '1/06/2014'\n",
      " '11/08/2014' '11/06/2014' '17/12/2013' '9/03/2014' '12/11/2014'\n",
      " '28/08/2014' '8/05/2015' '1/03/2014' '28/02/2015' '16/02/2014'\n",
      " '14/01/2014' '17/02/2013' '26/10/2013' '8/09/2013' '5/10/2014'\n",
      " '9/10/2014' '2/02/2014' '22/07/2013' '26/04/2015' '17/05/2014'\n",
      " '9/08/2014' '11/01/2015' '4/03/2013' '9/02/2014' '22/03/2014'\n",
      " '17/06/2013' '5/10/2013' '29/01/2013' '6/06/2014' '4/01/2013' '4/07/2014'\n",
      " '24/01/2013' '12/07/2014' '25/01/2013' '16/11/2013' '6/04/2013'\n",
      " '13/01/2013' '24/01/2014' '3/11/2013' '3/05/2014' '19/02/2015'\n",
      " '5/07/2014' '11/05/2015' '13/03/2013' '24/05/2014' '3/03/2013'\n",
      " '25/06/2013' '30/08/2014' '17/09/2014' '28/11/2014' '15/06/2014'\n",
      " '11/07/2013' '6/07/2014' '13/04/2014' '3/04/2013' '15/03/2014'\n",
      " '8/03/2013' '25/02/2013' '13/02/2015' '15/03/2015' '13/04/2013'\n",
      " '20/04/2013' '14/04/2013' '2/03/2013' '17/08/2013' '22/06/2014'\n",
      " '6/02/2015' '29/03/2013' '21/02/2015' '5/02/2015' '3/04/2015' '4/06/2013'\n",
      " '14/12/2013' '10/02/2014' '12/04/2014' '17/01/2015' '17/07/2014'\n",
      " '14/09/2014' '10/11/2013' '28/01/2013' '1/10/2013' '1/10/2014'\n",
      " '17/10/2013' '29/04/2013' '27/01/2014' '27/11/2014' '1/02/2014'\n",
      " '2/05/2013' '12/10/2013' '8/10/2014' '11/04/2015' '30/11/2014'\n",
      " '19/05/2013' '29/01/2015' '15/08/2014' '19/12/2014' '25/12/2013'\n",
      " '24/02/2013' '18/10/2014' '8/12/2013' '1/05/2013' '28/03/2015'\n",
      " '12/11/2013' '22/04/2014' '1/12/2013' '7/12/2014' '29/05/2013'\n",
      " '20/07/2013' '27/04/2013' '9/06/2013' '17/03/2013' '27/12/2014'\n",
      " '25/10/2014' '12/04/2015' '26/05/2013' '31/08/2013' '5/09/2014'\n",
      " '18/08/2013' '8/11/2013' '12/08/2014' '27/10/2013' '20/12/2013'\n",
      " '16/11/2014' '4/04/2013' '1/09/2013' '19/01/2013' '10/03/2013'\n",
      " '12/10/2014' '8/02/2014' '10/02/2013' '20/07/2014' '30/03/2013'\n",
      " '16/03/2013' '9/05/2015' '17/11/2013' '27/09/2014' '24/12/2013'\n",
      " '17/05/2013' '31/03/2013' '18/05/2014' '1/11/2014' '20/03/2013'\n",
      " '7/07/2013' '10/08/2014' '19/04/2013' '22/11/2014' '9/11/2013'\n",
      " '13/10/2013' '29/06/2014' '7/02/2015' '27/01/2013' '29/12/2013'\n",
      " '14/06/2014' '2/11/2014' '12/01/2013' '14/02/2015' '7/01/2013'\n",
      " '27/11/2013' '28/09/2013' '19/01/2014' '7/12/2013' '21/12/2013'\n",
      " '29/11/2013' '20/01/2013' '1/01/2013' '16/06/2013' '28/11/2013'\n",
      " '15/12/2013']\n",
      "868\n",
      "\n",
      "Personal_info1\n",
      "['N' 'Y' nan]\n",
      "3\n",
      "\n",
      "Personal_info2\n",
      "[11 -1  1 21  7 15  4  6 13 20 24 17  5  3 14  9 12 22  8 19 10 23 16 25\n",
      " 18  2]\n",
      "26\n",
      "\n",
      "Personal_info3\n",
      "['ZA' 'XX' 'ZN' 'ZH' 'YH' 'YF' 'ZC' 'ZG' 'XE' 'XQ' 'XR' 'XH' 'XD' 'XZ'\n",
      " 'XJ' 'ZT' 'XM' 'ZF' 'ZW' 'XB' 'XW' 'XS' 'XO' 'ZJ' 'YE' 'ZR' 'ZK' 'XK'\n",
      " 'XL' 'ZE' 'XC' 'ZD' 'XI' 'YI' 'ZU' 'XP' 'XT' 'XY' 'ZV' 'ZB' 'XF' 'ZP']\n",
      "42\n",
      "\n",
      "Personal_info4\n",
      "[0 3 1 2 6 4 7]\n",
      "7\n",
      "\n",
      "Personal_info5\n",
      "[ 2. nan  1.  5.  3.  7.]\n",
      "6\n",
      "\n",
      "Property_info1\n",
      "['N' 'Y' nan]\n",
      "3\n",
      "\n",
      "Property_info2\n",
      "[0]\n",
      "1\n",
      "\n",
      "Property_info3\n",
      "['S' 'R' 'O' 'Q' 'D' 'J' 'I' 'N' 'H' 'A' 'K' 'F' 'E' 'M' 'G' 'L' 'P' 'C'\n",
      " 'B']\n",
      "19\n",
      "\n",
      "Property_info4\n",
      "[0 1]\n",
      "2\n",
      "\n",
      "Property_info5\n",
      "[ 7 16  3 24 22 13  1 10 11 23  5 19  4 12 14  6 18  9  8 21 25 20 15  2\n",
      " 17 -1]\n",
      "26\n",
      "\n",
      "QuoteConversion_Flag\n",
      "[ 0.  1. nan]\n",
      "3\n",
      "\n",
      "Quote_ID\n",
      "[11405 21611 53649 ... 40427 61465 58463]\n",
      "78225\n",
      "\n",
      "Sales_info1\n",
      "[1 0]\n",
      "2\n",
      "\n",
      "Sales_info2\n",
      "[5 4 3 2 1]\n",
      "5\n",
      "\n",
      "Sales_info3\n",
      "[ 1 11  7 20 15  4 24 17 23  3 22 21 14 16  5  8 10 18 12 13  9  6 19  2]\n",
      "24\n",
      "\n",
      "Sales_info4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P' 'Q' 'T' 'K' 'M' 'R' 'V']\n",
      "7\n",
      "\n",
      "Sales_info5\n",
      "[38880 10725 46425 ... 56484 26612 62976]\n",
      "45889\n",
      "\n",
      "source\n",
      "['train' 'test']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for columns in df.columns.values.tolist():\n",
    "    print(\"\\n\" + columns)\n",
    "    print(df[columns].unique())\n",
    "    print(len(df[columns].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Coverage_info1 Coverage_info1\n",
      "-1      143\n",
      " 1     2781\n",
      " 2     4080\n",
      " 3     6338\n",
      " 4     8690\n",
      " 5     9372\n",
      " 6     9758\n",
      " 7     8850\n",
      " 8     8389\n",
      " 9     7040\n",
      " 10    6087\n",
      " 11    5546\n",
      " 12    4236\n",
      " 13    3803\n",
      " 14    2970\n",
      " 15    2602\n",
      " 16    2077\n",
      " 17    1805\n",
      " 18    1582\n",
      " 19    1313\n",
      " 20    1156\n",
      " 21     912\n",
      " 22     876\n",
      " 23     735\n",
      " 24     581\n",
      " 25    2579\n",
      "Name: Coverage_info1, dtype: int64\n",
      "\n",
      " Coverage_info2 Coverage_info2\n",
      "1       165\n",
      "2      6010\n",
      "22    84810\n",
      "25    13316\n",
      "Name: Coverage_info2, dtype: int64\n",
      "\n",
      " Coverage_info3 Coverage_info3\n",
      "A     5582\n",
      "B      443\n",
      "C      221\n",
      "D    19853\n",
      "E    34135\n",
      "F    12933\n",
      "G    13043\n",
      "H      228\n",
      "I      252\n",
      "J     6592\n",
      "K    10900\n",
      "L      119\n",
      "Name: Coverage_info3, dtype: int64\n",
      "\n",
      " Field_info1 Field_info1\n",
      "A       18\n",
      "B    38065\n",
      "C     2286\n",
      "D      102\n",
      "E    10470\n",
      "F    27544\n",
      "J    20557\n",
      "K     5259\n",
      "Name: Field_info1, dtype: int64\n",
      "\n",
      " Field_info2 Field_info2\n",
      "0.8746      732\n",
      "0.8793     1054\n",
      "0.8870     7354\n",
      "0.8922     4301\n",
      "0.8928     5595\n",
      "0.8930      487\n",
      "0.8945      893\n",
      "0.9023      817\n",
      "0.9108     1976\n",
      "0.9153    17706\n",
      "0.9194      469\n",
      "0.9219      972\n",
      "0.9223      836\n",
      "0.9258      514\n",
      "0.9313     1907\n",
      "0.9364      499\n",
      "0.9368      864\n",
      "0.9375      443\n",
      "0.9392     2911\n",
      "0.9403    19403\n",
      "0.9472     1306\n",
      "0.9482      738\n",
      "0.9485      406\n",
      "0.9487      787\n",
      "0.9489      366\n",
      "0.9497     1242\n",
      "0.9525      772\n",
      "0.9559     1153\n",
      "0.9566     1244\n",
      "0.9685     1007\n",
      "0.9691     3300\n",
      "0.9769     1305\n",
      "0.9838     2126\n",
      "0.9893      657\n",
      "0.9919     6757\n",
      "1.0005     1359\n",
      "1.0006     7280\n",
      "1.0101     2763\n",
      "Name: Field_info2, dtype: int64\n",
      "\n",
      " Field_info3 Field_info3\n",
      "1,113    17865\n",
      "1,165     7953\n",
      "1,480     4666\n",
      "1,487     8090\n",
      "548      15560\n",
      "564      12086\n",
      "935      20956\n",
      "965      17125\n",
      "Name: Field_info3, dtype: int64\n",
      "\n",
      " Field_info4 Field_info4\n",
      "N    96756\n",
      "Y     7545\n",
      "Name: Field_info4, dtype: int64\n",
      "\n",
      " Geographic_info1 Geographic_info1\n",
      "-1         1\n",
      " 1      3408\n",
      " 2     34711\n",
      " 3       367\n",
      " 4     27399\n",
      " 5       370\n",
      " 6       204\n",
      " 7       287\n",
      " 8       273\n",
      " 9      9187\n",
      " 10     1028\n",
      " 11     2556\n",
      " 12      493\n",
      " 13     1799\n",
      " 14     8305\n",
      " 15     1426\n",
      " 16       85\n",
      " 17      578\n",
      " 18      657\n",
      " 19      563\n",
      " 20      337\n",
      " 21      196\n",
      " 22      312\n",
      " 23      450\n",
      " 24     6384\n",
      " 25     2925\n",
      "Name: Geographic_info1, dtype: int64\n",
      "\n",
      " Geographic_info2 Geographic_info2\n",
      "-1         1\n",
      " 4     16633\n",
      " 5      3896\n",
      " 6      4467\n",
      " 7      4176\n",
      " 8      4112\n",
      " 9      4296\n",
      " 10     4152\n",
      " 11     4248\n",
      " 12     4203\n",
      " 13     4132\n",
      " 14     4063\n",
      " 15     4217\n",
      " 16     4127\n",
      " 17     4179\n",
      " 18     4129\n",
      " 19     4134\n",
      " 20     4159\n",
      " 21     3988\n",
      " 22     4436\n",
      " 23     4075\n",
      " 24     4288\n",
      " 25     4190\n",
      "Name: Geographic_info2, dtype: int64\n",
      "\n",
      " Geographic_info3 Geographic_info3\n",
      "-1     101740\n",
      " 25      2561\n",
      "Name: Geographic_info3, dtype: int64\n",
      "\n",
      " Geographic_info4 Geographic_info4\n",
      "          1\n",
      "N    101898\n",
      "Y      2402\n",
      "Name: Geographic_info4, dtype: int64\n",
      "\n",
      " Geographic_info5 Geographic_info5\n",
      "CA    38081\n",
      "IL    12756\n",
      "NJ    27646\n",
      "TX    25818\n",
      "Name: Geographic_info5, dtype: int64\n",
      "\n",
      " Original_Quote_Date Original_Quote_Date\n",
      "1/01/2013      20\n",
      "1/01/2014      55\n",
      "1/01/2015      63\n",
      "1/02/2013     113\n",
      "1/02/2014      90\n",
      "1/02/2015      39\n",
      "1/03/2013     115\n",
      "1/03/2014     123\n",
      "1/03/2015      80\n",
      "1/04/2013     118\n",
      "1/04/2014     197\n",
      "1/04/2015     183\n",
      "1/05/2013     127\n",
      "1/05/2014     126\n",
      "1/05/2015     149\n",
      "1/06/2013      74\n",
      "1/06/2014      56\n",
      "1/07/2013     191\n",
      "1/07/2014     205\n",
      "1/08/2013     186\n",
      "1/08/2014     124\n",
      "1/09/2013      68\n",
      "1/09/2014      52\n",
      "1/10/2013     180\n",
      "1/10/2014     140\n",
      "1/11/2013     126\n",
      "1/11/2014      65\n",
      "1/12/2013      29\n",
      "1/12/2014     135\n",
      "10/01/2013     89\n",
      "             ... \n",
      "8/12/2014     116\n",
      "9/01/2013      93\n",
      "9/01/2014     123\n",
      "9/01/2015     166\n",
      "9/02/2013      62\n",
      "9/02/2014      57\n",
      "9/02/2015     130\n",
      "9/03/2013      67\n",
      "9/03/2014      89\n",
      "9/03/2015     213\n",
      "9/04/2013     159\n",
      "9/04/2014     141\n",
      "9/04/2015     140\n",
      "9/05/2013     139\n",
      "9/05/2014     127\n",
      "9/05/2015      74\n",
      "9/06/2013      60\n",
      "9/06/2014     171\n",
      "9/07/2013     220\n",
      "9/07/2014     178\n",
      "9/08/2013     162\n",
      "9/08/2014      64\n",
      "9/09/2013     211\n",
      "9/09/2014     167\n",
      "9/10/2013     146\n",
      "9/10/2014     106\n",
      "9/11/2013      63\n",
      "9/11/2014      56\n",
      "9/12/2013      99\n",
      "9/12/2014     116\n",
      "Name: Original_Quote_Date, Length: 868, dtype: int64\n",
      "\n",
      " Personal_info1 Personal_info1\n",
      "N    103766\n",
      "Y       489\n",
      "Name: Personal_info1, dtype: int64\n",
      "\n",
      " Personal_info2 Personal_info2\n",
      "-1     21913\n",
      " 1      2059\n",
      " 2       433\n",
      " 3       991\n",
      " 4      6362\n",
      " 5     16877\n",
      " 6     15791\n",
      " 7      9584\n",
      " 8      3977\n",
      " 9      2323\n",
      " 10     2025\n",
      " 11     1703\n",
      " 12     1737\n",
      " 13     1532\n",
      " 14     1551\n",
      " 15     1499\n",
      " 16     1569\n",
      " 17     1316\n",
      " 18     1271\n",
      " 19     1190\n",
      " 20     1122\n",
      " 21     1269\n",
      " 22     1242\n",
      " 23     1438\n",
      " 24     1415\n",
      " 25     2112\n",
      "Name: Personal_info2, dtype: int64\n",
      "\n",
      " Personal_info3 Personal_info3\n",
      "XB     2713\n",
      "XC      524\n",
      "XD     3203\n",
      "XE      975\n",
      "XF        2\n",
      "XH     3033\n",
      "XI      372\n",
      "XJ     3948\n",
      "XK       55\n",
      "XL      167\n",
      "XM     3839\n",
      "XO     2759\n",
      "XP      107\n",
      "XQ      978\n",
      "XR     6087\n",
      "XS     1793\n",
      "XT        1\n",
      "XW     1054\n",
      "XX     3090\n",
      "XY        1\n",
      "XZ      253\n",
      "YE     1169\n",
      "YF     1529\n",
      "YH     2583\n",
      "YI       97\n",
      "ZA    49819\n",
      "ZB        3\n",
      "ZC      763\n",
      "ZD      345\n",
      "ZE      293\n",
      "ZF     1952\n",
      "ZG     1146\n",
      "ZH     2251\n",
      "ZJ      233\n",
      "ZK      371\n",
      "ZN     1794\n",
      "ZP        1\n",
      "ZR     1796\n",
      "ZT     2202\n",
      "ZU      108\n",
      "ZV        1\n",
      "ZW      891\n",
      "Name: Personal_info3, dtype: int64\n",
      "\n",
      " Personal_info4 Personal_info4\n",
      "0    104225\n",
      "1        55\n",
      "2        14\n",
      "3         4\n",
      "4         1\n",
      "6         1\n",
      "7         1\n",
      "Name: Personal_info4, dtype: int64\n",
      "\n",
      " Personal_info5 Personal_info5\n",
      "1.0      609\n",
      "2.0    54150\n",
      "3.0        3\n",
      "5.0       26\n",
      "7.0        1\n",
      "Name: Personal_info5, dtype: int64\n",
      "\n",
      " Property_info1 Property_info1\n",
      "N    90810\n",
      "Y    13460\n",
      "Name: Property_info1, dtype: int64\n",
      "\n",
      " Property_info2 Property_info2\n",
      "0    104301\n",
      "Name: Property_info2, dtype: int64\n",
      "\n",
      " Property_info3 Property_info3\n",
      "A     1588\n",
      "B        1\n",
      "C        1\n",
      "D    11256\n",
      "E      346\n",
      "F      198\n",
      "G       59\n",
      "H      568\n",
      "I     3587\n",
      "J    14185\n",
      "K      736\n",
      "L      267\n",
      "M       12\n",
      "N     4818\n",
      "O    29873\n",
      "P        3\n",
      "Q     2334\n",
      "R    27650\n",
      "S     6819\n",
      "Name: Property_info3, dtype: int64\n",
      "\n",
      " Property_info4 Property_info4\n",
      "0    34956\n",
      "1    69345\n",
      "Name: Property_info4, dtype: int64\n",
      "\n",
      " Property_info5 Property_info5\n",
      "-1       10\n",
      " 1     4147\n",
      " 2     4215\n",
      " 3     4204\n",
      " 4     4196\n",
      " 5     4147\n",
      " 6     4109\n",
      " 7     4067\n",
      " 8     4154\n",
      " 9     4295\n",
      " 10    4143\n",
      " 11    4204\n",
      " 12    4226\n",
      " 13    4204\n",
      " 14    4209\n",
      " 15    4134\n",
      " 16    4103\n",
      " 17    4166\n",
      " 18    4147\n",
      " 19    4187\n",
      " 20    4114\n",
      " 21    4190\n",
      " 22    4205\n",
      " 23    4169\n",
      " 24    4248\n",
      " 25    4108\n",
      "Name: Property_info5, dtype: int64\n",
      "\n",
      " QuoteConversion_Flag QuoteConversion_Flag\n",
      "0.0    63315\n",
      "1.0    14910\n",
      "Name: QuoteConversion_Flag, dtype: int64\n",
      "\n",
      " Quote_ID Quote_ID\n",
      "1        2\n",
      "2        2\n",
      "3        2\n",
      "4        2\n",
      "5        2\n",
      "6        2\n",
      "7        2\n",
      "8        2\n",
      "9        2\n",
      "10       2\n",
      "11       2\n",
      "12       2\n",
      "13       2\n",
      "14       2\n",
      "15       2\n",
      "16       2\n",
      "17       2\n",
      "18       2\n",
      "19       2\n",
      "20       2\n",
      "21       2\n",
      "22       2\n",
      "23       2\n",
      "24       2\n",
      "25       2\n",
      "26       2\n",
      "27       2\n",
      "28       2\n",
      "29       2\n",
      "30       2\n",
      "        ..\n",
      "78196    1\n",
      "78197    1\n",
      "78198    1\n",
      "78199    1\n",
      "78200    1\n",
      "78201    1\n",
      "78202    1\n",
      "78203    1\n",
      "78204    1\n",
      "78205    1\n",
      "78206    1\n",
      "78207    1\n",
      "78208    1\n",
      "78209    1\n",
      "78210    1\n",
      "78211    1\n",
      "78212    1\n",
      "78213    1\n",
      "78214    1\n",
      "78215    1\n",
      "78216    1\n",
      "78217    1\n",
      "78218    1\n",
      "78219    1\n",
      "78220    1\n",
      "78221    1\n",
      "78222    1\n",
      "78223    1\n",
      "78224    1\n",
      "78225    1\n",
      "Name: Quote_ID, Length: 78225, dtype: int64\n",
      "\n",
      " Sales_info1 Sales_info1\n",
      "0    26656\n",
      "1    77645\n",
      "Name: Sales_info1, dtype: int64\n",
      "\n",
      " Sales_info2 Sales_info2\n",
      "1        2\n",
      "2     5180\n",
      "3    25369\n",
      "4    14591\n",
      "5    59159\n",
      "Name: Sales_info2, dtype: int64\n",
      "\n",
      " Sales_info3 Sales_info3\n",
      "1      5646\n",
      "2         3\n",
      "3       491\n",
      "4      5048\n",
      "5         5\n",
      "6         5\n",
      "7      5773\n",
      "8       853\n",
      "9        10\n",
      "10     1000\n",
      "11    35674\n",
      "12        9\n",
      "13       34\n",
      "14     2467\n",
      "15     3161\n",
      "16     1044\n",
      "17     3365\n",
      "18      219\n",
      "19        1\n",
      "20    25880\n",
      "21     3713\n",
      "22     1817\n",
      "23     6420\n",
      "24     1663\n",
      "Name: Sales_info3, dtype: int64\n",
      "\n",
      " Sales_info4 Sales_info4\n",
      "K    20015\n",
      "M     6488\n",
      "P    19786\n",
      "Q    16367\n",
      "R     8196\n",
      "T    18110\n",
      "V    15339\n",
      "Name: Sales_info4, dtype: int64\n",
      "\n",
      " Sales_info5 Sales_info5\n",
      "4        1\n",
      "5        2\n",
      "6        2\n",
      "8        2\n",
      "9        3\n",
      "10       1\n",
      "12       2\n",
      "14       4\n",
      "17       1\n",
      "18       2\n",
      "19       3\n",
      "20       1\n",
      "21       2\n",
      "22       3\n",
      "23       1\n",
      "24       4\n",
      "27       1\n",
      "28       1\n",
      "29       3\n",
      "30       2\n",
      "31       1\n",
      "32       1\n",
      "33       2\n",
      "34       1\n",
      "35       1\n",
      "36       6\n",
      "37       1\n",
      "39       2\n",
      "40       4\n",
      "42       1\n",
      "        ..\n",
      "67120    2\n",
      "67122    2\n",
      "67123    1\n",
      "67124    3\n",
      "67125    2\n",
      "67126    3\n",
      "67127    4\n",
      "67128    4\n",
      "67130    1\n",
      "67131    1\n",
      "67132    3\n",
      "67135    3\n",
      "67136    2\n",
      "67138    6\n",
      "67142    1\n",
      "67143    1\n",
      "67144    2\n",
      "67145    1\n",
      "67146    1\n",
      "67148    1\n",
      "67149    1\n",
      "67150    2\n",
      "67154    2\n",
      "67155    1\n",
      "67156    3\n",
      "67157    3\n",
      "67158    1\n",
      "67161    1\n",
      "67162    3\n",
      "67164    2\n",
      "Name: Sales_info5, Length: 45889, dtype: int64\n",
      "\n",
      " source source\n",
      "test     26076\n",
      "train    78225\n",
      "Name: source, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    gf = df.groupby(col)[col].count()\n",
    "    print ('\\n',col, gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Personal_info2 Personal_info1\n",
      "N    [11, -1, 1, 21, 7, 15, 4, 6, 13, 20, 24, 17, 5...\n",
      "Y    [3, 22, -1, 7, 24, 5, 10, 6, 1, 9, 4, 12, 19, ...\n",
      "Name: Personal_info2, dtype: object\n",
      "\n",
      " Personal_info3 Personal_info1\n",
      "N    [ZA, XX, ZN, ZH, YH, YF, ZC, ZG, XE, XQ, XR, X...\n",
      "Y    [XB, ZA, XX, YF, XM, ZH, XR, XQ, ZG, ZT, ZE, X...\n",
      "Name: Personal_info3, dtype: object\n",
      "\n",
      " Personal_info4 Personal_info1\n",
      "N    [0, 3, 1, 2, 6, 4, 7]\n",
      "Y                      [0]\n",
      "Name: Personal_info4, dtype: object\n",
      "\n",
      " Personal_info5 Personal_info1\n",
      "N    [2.0, nan, 1.0, 5.0, 3.0, 7.0]\n",
      "Y                   [nan, 2.0, 1.0]\n",
      "Name: Personal_info5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in ['Personal_info2', 'Personal_info3', 'Personal_info4', 'Personal_info5']:\n",
    "    gf = df.groupby('Personal_info1')[col].unique()\n",
    "    print ('\\n',col, gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df[df['Personal_info1'].isnull()].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104301 entries, 0 to 104300\n",
      "Data columns (total 31 columns):\n",
      "Coverage_info1          104301 non-null int64\n",
      "Coverage_info2          104301 non-null int64\n",
      "Coverage_info3          104301 non-null object\n",
      "Field_info1             104301 non-null object\n",
      "Field_info2             104301 non-null float64\n",
      "Field_info3             104301 non-null object\n",
      "Field_info4             104301 non-null object\n",
      "Geographic_info1        104301 non-null int64\n",
      "Geographic_info2        104301 non-null int64\n",
      "Geographic_info3        104301 non-null int64\n",
      "Geographic_info4        104301 non-null object\n",
      "Geographic_info5        104301 non-null object\n",
      "Original_Quote_Date     104301 non-null object\n",
      "Personal_info1          104301 non-null object\n",
      "Personal_info2          104301 non-null int64\n",
      "Personal_info3          104301 non-null object\n",
      "Personal_info4          104301 non-null int64\n",
      "Personal_info5          54789 non-null float64\n",
      "Property_info1          104270 non-null object\n",
      "Property_info2          104301 non-null int64\n",
      "Property_info3          104301 non-null object\n",
      "Property_info4          104301 non-null int64\n",
      "Property_info5          104301 non-null int64\n",
      "QuoteConversion_Flag    78225 non-null float64\n",
      "Quote_ID                104301 non-null int64\n",
      "Sales_info1             104301 non-null int64\n",
      "Sales_info2             104301 non-null int64\n",
      "Sales_info3             104301 non-null int64\n",
      "Sales_info4             104301 non-null object\n",
      "Sales_info5             104301 non-null int64\n",
      "source                  104301 non-null object\n",
      "dtypes: float64(3), int64(15), object(13)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "for i in missing:    \n",
    "    val = (df[df['Personal_info2'] == df.loc[i,'Personal_info2']]['Personal_info1'].mode()).values\n",
    "    df.loc[i,'Personal_info1'] = val[0]\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Personal_info1 Personal_info5\n",
      "1.0    [N, Y]\n",
      "2.0    [N, Y]\n",
      "3.0       [N]\n",
      "5.0       [N]\n",
      "7.0       [N]\n",
      "Name: Personal_info1, dtype: object\n",
      "\n",
      " Personal_info2 Personal_info5\n",
      "1.0    [4, 5, 6, 3, 7, 12, 11, -1, 10, 8, 19, 16, 24,...\n",
      "2.0    [11, 1, -1, 21, 7, 4, 6, 24, 5, 14, 12, 3, 8, ...\n",
      "3.0                                          [20, 5, 11]\n",
      "5.0          [14, 5, 6, 7, 19, 25, 10, 21, -1, 4, 9, 11]\n",
      "7.0                                                 [14]\n",
      "Name: Personal_info2, dtype: object\n",
      "\n",
      " Personal_info3 Personal_info5\n",
      "1.0    [ZA, YE, XR, XS, ZT, ZN, YH, XB, XH, ZH, XX, Y...\n",
      "2.0    [ZA, XE, ZW, XW, XH, XD, XS, XR, XJ, YE, XX, Z...\n",
      "3.0                                         [XO, ZN, ZH]\n",
      "5.0    [ZF, XR, XX, XD, XW, XJ, YH, YE, XL, YF, XE, X...\n",
      "7.0                                                 [ZC]\n",
      "Name: Personal_info3, dtype: object\n",
      "\n",
      " Personal_info4 Personal_info5\n",
      "1.0          [0, 1, 4, 3]\n",
      "2.0    [0, 3, 1, 2, 6, 7]\n",
      "3.0                   [0]\n",
      "5.0                   [0]\n",
      "7.0                   [0]\n",
      "Name: Personal_info4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for col in ['Personal_info1', 'Personal_info2', 'Personal_info3', 'Personal_info4']:\n",
    "    gf = df.groupby('Personal_info5')[col].unique()\n",
    "    print ('\\n',col, gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104301 entries, 0 to 104300\n",
      "Data columns (total 31 columns):\n",
      "Coverage_info1          104301 non-null int64\n",
      "Coverage_info2          104301 non-null int64\n",
      "Coverage_info3          104301 non-null object\n",
      "Field_info1             104301 non-null object\n",
      "Field_info2             104301 non-null float64\n",
      "Field_info3             104301 non-null object\n",
      "Field_info4             104301 non-null object\n",
      "Geographic_info1        104301 non-null int64\n",
      "Geographic_info2        104301 non-null int64\n",
      "Geographic_info3        104301 non-null int64\n",
      "Geographic_info4        104301 non-null object\n",
      "Geographic_info5        104301 non-null object\n",
      "Original_Quote_Date     104301 non-null object\n",
      "Personal_info1          104301 non-null object\n",
      "Personal_info2          104301 non-null int64\n",
      "Personal_info3          104301 non-null object\n",
      "Personal_info4          104301 non-null int64\n",
      "Personal_info5          104301 non-null float64\n",
      "Property_info1          104270 non-null object\n",
      "Property_info2          104301 non-null int64\n",
      "Property_info3          104301 non-null object\n",
      "Property_info4          104301 non-null int64\n",
      "Property_info5          104301 non-null int64\n",
      "QuoteConversion_Flag    78225 non-null float64\n",
      "Quote_ID                104301 non-null int64\n",
      "Sales_info1             104301 non-null int64\n",
      "Sales_info2             104301 non-null int64\n",
      "Sales_info3             104301 non-null int64\n",
      "Sales_info4             104301 non-null object\n",
      "Sales_info5             104301 non-null int64\n",
      "source                  104301 non-null object\n",
      "dtypes: float64(3), int64(15), object(13)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "missing = df[df['Personal_info5'].isnull()].index.tolist()\n",
    "\n",
    "for i in missing:\n",
    "    val = (df[df['Personal_info1'] == df.loc[i,'Personal_info1']]['Personal_info5'].mode()).values\n",
    "    df.loc[i,'Personal_info5'] = val[0]\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Property_info1\n",
      "N    [S, R, O, Q, D, J, N, H, I, A, K, F, E, M, G, ...\n",
      "Y        [O, I, R, S, N, J, D, Q, K, H, E, A, F, L, G]\n",
      "Name: Property_info3, dtype: object\n",
      "\n",
      " Property_info1\n",
      "N    [0, 1]\n",
      "Y    [1, 0]\n",
      "Name: Property_info4, dtype: object\n",
      "\n",
      " Property_info1\n",
      "N    [7, 16, 3, 24, 22, 13, 1, 10, 11, 5, 19, 4, 12...\n",
      "Y    [23, 13, 10, 12, 4, 20, 22, 24, 16, 25, 3, 17,...\n",
      "Name: Property_info5, dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104301 entries, 0 to 104300\n",
      "Data columns (total 31 columns):\n",
      "Coverage_info1          104301 non-null int64\n",
      "Coverage_info2          104301 non-null int64\n",
      "Coverage_info3          104301 non-null object\n",
      "Field_info1             104301 non-null object\n",
      "Field_info2             104301 non-null float64\n",
      "Field_info3             104301 non-null object\n",
      "Field_info4             104301 non-null object\n",
      "Geographic_info1        104301 non-null int64\n",
      "Geographic_info2        104301 non-null int64\n",
      "Geographic_info3        104301 non-null int64\n",
      "Geographic_info4        104301 non-null object\n",
      "Geographic_info5        104301 non-null object\n",
      "Original_Quote_Date     104301 non-null object\n",
      "Personal_info1          104301 non-null object\n",
      "Personal_info2          104301 non-null int64\n",
      "Personal_info3          104301 non-null object\n",
      "Personal_info4          104301 non-null int64\n",
      "Personal_info5          104301 non-null float64\n",
      "Property_info1          104301 non-null object\n",
      "Property_info2          104301 non-null int64\n",
      "Property_info3          104301 non-null object\n",
      "Property_info4          104301 non-null int64\n",
      "Property_info5          104301 non-null int64\n",
      "QuoteConversion_Flag    78225 non-null float64\n",
      "Quote_ID                104301 non-null int64\n",
      "Sales_info1             104301 non-null int64\n",
      "Sales_info2             104301 non-null int64\n",
      "Sales_info3             104301 non-null int64\n",
      "Sales_info4             104301 non-null object\n",
      "Sales_info5             104301 non-null int64\n",
      "source                  104301 non-null object\n",
      "dtypes: float64(3), int64(15), object(13)\n",
      "memory usage: 24.7+ MB\n"
     ]
    }
   ],
   "source": [
    "for col in ['Property_info3', 'Property_info4', 'Property_info5']:\n",
    "    gf = df.groupby('Property_info1')[col].unique()\n",
    "    print ('\\n', gf)\n",
    "    \n",
    "missing = df[df['Property_info1'].isnull()].index.tolist()\n",
    "\n",
    "for i in missing:\n",
    "    val = (df[df['Property_info3'] == df.loc[i,'Property_info3']]['Property_info1'].mode()).values\n",
    "    df.loc[i,'Property_info1'] = val[0]\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Original_Quote_Days'] = pd.to_datetime(df['Original_Quote_Date'], format='%d/%m/%Y')\n",
    "today = np.datetime64(date.today())\n",
    "\n",
    "df['Original_Quote_Days'] = (today-df['Original_Quote_Days']).astype(str)\n",
    "df['Original_Quote_Days'] = df['Original_Quote_Days'].map(lambda x: x.replace(' days 00:00:00.000000000', \"\"))\n",
    "df['Original_Quote_Days'] = df['Original_Quote_Days'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Geographic_info4\", \"Property_info1\", \"Personal_info1\", 'Geographic_info5', \"Field_info1\", \"Field_info3\", 'Field_info4',\t'Coverage_info3',\t'Sales_info4',\t'Personal_info3',\"Property_info3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Property_info2',\"Original_Quote_Date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[df['source'] == \"train\"]\n",
    "df_test = df.loc[df['source'] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enc_obj = df_train.drop([\"QuoteConversion_Flag\", \"source\"], axis=1)\n",
    "X_enc_targets = df_train['QuoteConversion_Flag']\n",
    "\n",
    "X_enc_test_obj = df_test.drop([\"QuoteConversion_Flag\", \"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_enc_obj, X_enc_targets, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78225 entries, 0 to 78224\n",
      "Data columns (total 49 columns):\n",
      "Coverage_info2          78225 non-null int64\n",
      "Field_info2             78225 non-null float64\n",
      "Geographic_info1        78225 non-null int64\n",
      "Geographic_info2        78225 non-null int64\n",
      "Geographic_info3        78225 non-null int64\n",
      "Personal_info2          78225 non-null int64\n",
      "Personal_info4          78225 non-null int64\n",
      "Personal_info5          78225 non-null float64\n",
      "Property_info4          78225 non-null int64\n",
      "Property_info5          78225 non-null int64\n",
      "QuoteConversion_Flag    78225 non-null float64\n",
      "Quote_ID                78225 non-null int64\n",
      "Sales_info1             78225 non-null int64\n",
      "Sales_info2             78225 non-null int64\n",
      "Sales_info3             78225 non-null int64\n",
      "Sales_info5             78225 non-null int64\n",
      "source                  78225 non-null object\n",
      "Original_Quote_Days     78225 non-null int64\n",
      "Geographic_info4_       78225 non-null uint8\n",
      "Geographic_info4_N      78225 non-null uint8\n",
      "Geographic_info4_Y      78225 non-null uint8\n",
      "Property_info1_N        78225 non-null uint8\n",
      "Property_info1_Y        78225 non-null uint8\n",
      "Personal_info1_N        78225 non-null uint8\n",
      "Personal_info1_Y        78225 non-null uint8\n",
      "Geographic_info5_CA     78225 non-null uint8\n",
      "Geographic_info5_IL     78225 non-null uint8\n",
      "Geographic_info5_NJ     78225 non-null uint8\n",
      "Geographic_info5_TX     78225 non-null uint8\n",
      "Field_info1_A           78225 non-null uint8\n",
      "Field_info1_B           78225 non-null uint8\n",
      "Field_info1_C           78225 non-null uint8\n",
      "Field_info1_D           78225 non-null uint8\n",
      "Field_info1_E           78225 non-null uint8\n",
      "Field_info1_F           78225 non-null uint8\n",
      "Field_info1_J           78225 non-null uint8\n",
      "Field_info1_K           78225 non-null uint8\n",
      "Field_info3_1,113       78225 non-null uint8\n",
      "Field_info3_1,165       78225 non-null uint8\n",
      "Field_info3_1,480       78225 non-null uint8\n",
      "Field_info3_1,487       78225 non-null uint8\n",
      "Field_info3_548         78225 non-null uint8\n",
      "Field_info3_564         78225 non-null uint8\n",
      "Field_info3_935         78225 non-null uint8\n",
      "Field_info3_965         78225 non-null uint8\n",
      "Field_info4_N           78225 non-null uint8\n",
      "Field_info4_Y           78225 non-null uint8\n",
      "Coverage_info3_A        78225 non-null uint8\n",
      "Coverage_info3_B        78225 non-null uint8\n",
      "dtypes: float64(3), int64(14), object(1), uint8(31)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.iloc[:,1:50].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create logistic regression\n",
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "max_iter = [300, 500, 700]\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty, max_iter=max_iter)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "logr_gs = GridSearchCV(logr, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8093148116584284"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit grid search\n",
    "best_model = logr_gs.fit(train_x, train_y)\n",
    "\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "\n",
    "# Predict target vector\n",
    "best_model.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9885676717132056\n",
      "Out-of-Bag Score: 0.8196577606516062\n",
      "Testing score 0.8338588716550196\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create random forest classifer object that uses entropy\n",
    "rf = RandomForestClassifier(oob_score=True)\n",
    "\n",
    "# Train model\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "print(\"Training score:\", rf.score(train_x, train_y))\n",
    "print(\"Out-of-Bag Score:\", rf.oob_score_)\n",
    "print(\"Testing score\", rf.score(test_x,test_y))\n",
    "\n",
    "rf.score(test_x, test_y)\n",
    "pred_test = rf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Tree Training Score: 0.8679986120496009\n",
      "Gradient Boosting Tree Testing Score: 0.8550792568604056\n",
      "Gradient Boosting estimators: 500\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "gb = ensemble.GradientBoostingClassifier(n_estimators=500,\n",
    "                                             random_state=0)\n",
    "gb.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Tree Training Score:\", gb.score(train_x, train_y))\n",
    "print(\"Gradient Boosting Tree Testing Score:\", gb.score(test_x, test_y))\n",
    "print(\"Gradient Boosting estimators:\", gb.n_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coverage_info1', 0.054975993832959945)\n",
      "('Coverage_info2', 0.01751142114159131)\n",
      "('Field_info2', 0.021932424404471008)\n",
      "('Geographic_info1', 0.01738883168461209)\n",
      "('Geographic_info2', 0.03692151966872823)\n",
      "('Geographic_info3', 0.003014158494482598)\n",
      "('Personal_info2', 0.12175447669154187)\n",
      "('Personal_info4', 0.0005245618977347036)\n",
      "('Personal_info5', 0.003429962794178504)\n",
      "('Property_info4', 0.013312887231089006)\n",
      "('Property_info5', 0.05431957598428319)\n",
      "('QuoteConversion_Flag', 0.06848737055389709)\n",
      "('Quote_ID', 0.013835759800589594)\n",
      "('Sales_info1', 0.09998517005411543)\n",
      "('Sales_info2', 0.03813385955369956)\n",
      "('Sales_info3', 0.0695842271372382)\n",
      "('Sales_info5', 0.06818422768566489)\n",
      "('source', 0.0)\n",
      "('Original_Quote_Days', 0.0018840945088205627)\n",
      "('Geographic_info4_ ', 0.0018190698269733305)\n",
      "('Geographic_info4_N', 0.007556680114138496)\n",
      "('Geographic_info4_Y', 0.007129881300037295)\n",
      "('Property_info1_N', 0.0008119696449706623)\n",
      "('Property_info1_Y', 0.0006199791945706411)\n",
      "('Personal_info1_N', 0.0006360776280760258)\n",
      "('Personal_info1_Y', 0.0007252089838622901)\n",
      "('Geographic_info5_CA', 0.008970283334933543)\n",
      "('Geographic_info5_IL', 0.0004830606503161778)\n",
      "('Geographic_info5_NJ', 5.354666778844824e-05)\n",
      "('Geographic_info5_TX', 0.0032025823046083553)\n",
      "('Field_info1_A', 0.00023050849510154224)\n",
      "('Field_info1_B', 0.00024926907349906994)\n",
      "('Field_info1_C', 0.0009302867965532663)\n",
      "('Field_info1_D', 0.011228713630930622)\n",
      "('Field_info1_E', 0.0013192806792569976)\n",
      "('Field_info1_F', 0.0003575687092529433)\n",
      "('Field_info1_J', 0.002750576156776255)\n",
      "('Field_info1_K', 0.0012121664283724607)\n",
      "('Field_info3_1,113', 0.0006026039776153084)\n",
      "('Field_info3_1,165', 0.0012835219659255923)\n",
      "('Field_info3_1,480', 0.0019900059045558226)\n",
      "('Field_info3_1,487', 0.003810952699155325)\n",
      "('Field_info3_548', 0.005797285722353642)\n",
      "('Field_info3_564', 0.003442809368281917)\n",
      "('Field_info3_935', 0.0005891258690013974)\n",
      "('Field_info3_965', 0.000724836755729626)\n",
      "('Field_info4_N', 0.0018196044928770721)\n",
      "('Field_info4_Y', 0.0005341435775137464)\n",
      "('Coverage_info3_A', 0.0003004318394366957)\n",
      "('Coverage_info3_B', 0.00849376131998725)\n",
      "('Coverage_info3_C', 0.024647953789280298)\n",
      "('Coverage_info3_D', 0.003560672292564462)\n",
      "('Coverage_info3_E', 0.0027261338335028942)\n",
      "('Coverage_info3_F', 0.00028608278813438724)\n",
      "('Coverage_info3_G', 8.686319639831001e-05)\n",
      "('Coverage_info3_H', 0.0063541533354186976)\n",
      "('Coverage_info3_I', 0.006664762250450647)\n",
      "('Coverage_info3_J', 5.798685181657252e-05)\n",
      "('Coverage_info3_K', 0.010459829488597281)\n",
      "('Coverage_info3_L', 0.004468282553850716)\n",
      "('Sales_info4_K', 0.010225570630657028)\n",
      "('Sales_info4_M', 0.008792225365592878)\n",
      "('Sales_info4_P', 0.006268565312922)\n",
      "('Sales_info4_Q', 0.009421301225679113)\n",
      "('Sales_info4_R', 0.009775934565245526)\n",
      "('Sales_info4_T', 0.003410452342062105)\n",
      "('Sales_info4_V', 0.0010253867466143744)\n",
      "('Personal_info3_XB', 0.0038700157474115156)\n",
      "('Personal_info3_XC', 0.0016316687856200787)\n",
      "('Personal_info3_XD', 0.0)\n",
      "('Personal_info3_XE', 0.002539732710122702)\n",
      "('Personal_info3_XF', 0.0005929883851123013)\n",
      "('Personal_info3_XH', 0.004068323101931671)\n",
      "('Personal_info3_XI', 0.00022350162215840108)\n",
      "('Personal_info3_XJ', 0.00042020053469104743)\n",
      "('Personal_info3_XK', 0.0051197311092219325)\n",
      "('Personal_info3_XL', 0.0022658144178265933)\n",
      "('Personal_info3_XM', 0.0004726505392733265)\n",
      "('Personal_info3_XO', 0.0017273935097486457)\n",
      "('Personal_info3_XP', 0.005259548408522216)\n",
      "('Personal_info3_XQ', 0.0022824638767103976)\n",
      "('Personal_info3_XR', 0.0)\n",
      "('Personal_info3_XS', 0.0015612652781203567)\n",
      "('Personal_info3_XT', 0.0027689062151566553)\n",
      "('Personal_info3_XW', 2.835978560347628e-05)\n",
      "('Personal_info3_XX', 0.0007860527529764236)\n",
      "('Personal_info3_XY', 0.0020010707321840553)\n",
      "('Personal_info3_XZ', 0.0023605605886550074)\n",
      "('Personal_info3_YE', 0.0026264931357844906)\n",
      "('Personal_info3_YF', 0.00027321303145343)\n",
      "('Personal_info3_YH', 0.002884555769807977)\n",
      "('Personal_info3_YI', 0.0)\n",
      "('Personal_info3_ZA', 0.0012441179078809337)\n",
      "('Personal_info3_ZB', 0.0005924830004553229)\n",
      "('Personal_info3_ZC', 0.000400354790668708)\n",
      "('Personal_info3_ZD', 0.0025277609925781846)\n",
      "('Personal_info3_ZE', 0.0018438640193496805)\n",
      "('Personal_info3_ZF', 0.002463887451304563)\n",
      "('Personal_info3_ZG', 0.0006088359375104168)\n",
      "('Personal_info3_ZH', 0.0009174105016203269)\n",
      "('Personal_info3_ZJ', 0.002377689274964101)\n",
      "('Personal_info3_ZK', 3.237991747961638e-05)\n",
      "('Personal_info3_ZN', 0.002758870531241733)\n",
      "('Personal_info3_ZP', 0.0030069157462474013)\n",
      "('Personal_info3_ZR', 0.0002951858512833549)\n",
      "('Personal_info3_ZT', 9.792460564519323e-06)\n",
      "('Personal_info3_ZU', 0.001735874648721336)\n",
      "('Personal_info3_ZV', 0.0020490574098148456)\n",
      "('Personal_info3_ZW', 0.0)\n",
      "('Property_info3_A', 0.0)\n",
      "('Property_info3_B', 0.00676436341919904)\n",
      "('Property_info3_C', 0.0007296642114919785)\n",
      "('Property_info3_D', 8.949093118556461e-05)\n",
      "('Property_info3_E', 9.569026565737601e-05)\n",
      "('Property_info3_F', 0.001002060484238314)\n",
      "('Property_info3_G', 0.0024722514491411353)\n",
      "('Property_info3_H', 0.004260928170597728)\n",
      "('Property_info3_I', 0.0012027147151395716)\n",
      "('Property_info3_J', 0.0003263694087735413)\n",
      "('Property_info3_K', 1.8492183985880962e-05)\n",
      "('Property_info3_L', 0.003631748716620439)\n",
      "('Property_info3_M', 0.005647346924989427)\n",
      "('Property_info3_N', 0.0)\n",
      "('Property_info3_O', 0.001444242407564543)\n",
      "('Property_info3_P', 0.007584027050051588)\n",
      "('Property_info3_Q', 0.0030131463806490357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                 class_weight=None,\n",
       "                                                 criterion='gini',\n",
       "                                                 max_depth=None,\n",
       "                                                 max_features='auto',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=10, n_jobs=None,\n",
       "                                                 oob_score=True,\n",
       "                                                 random_state=None, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=0.01)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "feat_labels = df_train.columns.tolist()\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feat_labels, rf.feature_importances_):\n",
    "    print(feature)\n",
    "    \n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(rf, threshold=0.01)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage_info1\n",
      "Coverage_info2\n",
      "Field_info2\n",
      "Geographic_info1\n",
      "Geographic_info2\n",
      "Personal_info2\n",
      "Property_info4\n",
      "Property_info5\n",
      "QuoteConversion_Flag\n",
      "Quote_ID\n",
      "Sales_info1\n",
      "Sales_info2\n",
      "Sales_info3\n",
      "Sales_info5\n",
      "Coverage_info3_C\n",
      "Coverage_info3_K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n",
    "    \n",
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(train_x)\n",
    "X_important_test = sfm.transform(test_x)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8328788137037668"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred = rf.predict(test_x)\n",
    "\n",
    "# View The Accuracy Of Our Full Feature (4 Features) Model\n",
    "accuracy_score(test_y, y_pred)\n",
    "\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "accuracy_score(test_y, y_important_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809357707690341\n",
      "0.809485256519516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=100.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                max_iter=200, normalize=True, random_state=None, solver='auto',\n",
       "                tol=0.001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "rgc = RidgeClassifier(alpha=100.0, solver='auto', max_iter=200, normalize=True)\n",
    "rgc.fit(train_x, train_y)\n",
    "print(rgc.score(train_x, train_y))\n",
    "\n",
    "print(rgc.score(test_x, test_y))\n",
    "rgc.fit(X_important_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'solver': ['auto', 'sparse_cg', 'lsqr', 'sag'],\n",
    "                     'class_weight': 'balanced'}]\n",
    "                    \n",
    "scores = ['precision', 'recall']\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "model = RidgeClassifier(normalize=True, random_state=100, tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1.0}\n",
      "Best Test score for this model\n",
      "0.8096983125958752\n"
     ]
    }
   ],
   "source": [
    "rgc_gs = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "rgc_gs.fit(train_x, train_y)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(rgc_gs.best_params_)\n",
    "print(\"Best Test score for this model\")\n",
    "print(rgc_gs.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 1.0}\n",
      "Best Test score for this model\n",
      "0.809485256519516\n"
     ]
    }
   ],
   "source": [
    "rgc_gs.fit(X_important_train, train_y)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(rgc_gs.best_params_)\n",
    "print(\"Best Test score for this model\")\n",
    "print(rgc_gs.score(X_important_test, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809357707690341\n",
      "0.809485256519516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(256, 1), validation_fraction=0.3, early_stopping=False, random_state=1)\n",
    "nn.fit(train_x, train_y)\n",
    "\n",
    "print(nn.score(train_x, train_y))\n",
    "print(nn.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809357707690341\n",
      "0.809485256519516\n",
      "Gradient Boosting Tree Score: 0.8514573035622977\n",
      "Gradient Boosting estimators: 500\n"
     ]
    }
   ],
   "source": [
    "nn2 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(256, 1), validation_fraction=0.3, early_stopping=True, random_state=1)\n",
    "nn2.fit(X_important_train, train_y)\n",
    "print(nn2.score(X_important_train, train_y))\n",
    "print(nn2.score(X_important_test, test_y))\n",
    "\n",
    "gb2 = ensemble.GradientBoostingClassifier(n_estimators=500,\n",
    "                                             random_state=0)\n",
    "gb2.fit(X_important_train, train_y)\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Tree Score:\", gb2.score(X_important_test, test_y))\n",
    "print(\"Gradient Boosting estimators:\", gb2.n_estimators_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: (88641, 126) (88641,)\n",
      "Size of testing data (37989, 126) (37989,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_enc_obj, X_enc_targets)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=2)\n",
    "print(\"Size of training data:\", xtrain.shape, ytrain.shape)\n",
    "print(\"Size of testing data\", xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(256, 1), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.3, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5010322536974989"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49759140803916924"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RidgeClassifier(alpha=1.0, class_weight=None,\n",
       "                                       copy_X=True, fit_intercept=True,\n",
       "                                       max_iter=None, normalize=True,\n",
       "                                       random_state=100, solver='auto',\n",
       "                                       tol=0.1),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 0.e+00])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgc_gs.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7587797971593281"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgc_gs.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759772565742715"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgc_gs.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916280276621428"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9118165784832452"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb.predict(X_enc_test_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Dataset Training score: 0.9931295901445155\n",
      "Balanced Dataset Out-Of-Bag score: 0.8793447727349646\n",
      "Balanced Dataset Testing score: 0.8962067967043091\n"
     ]
    }
   ],
   "source": [
    "rf.fit(xtrain, ytrain)\n",
    "print(\"Balanced Dataset Training score:\", rf.score(xtrain, ytrain))\n",
    "print(\"Balanced Dataset Out-Of-Bag score:\", rf.oob_score_)\n",
    "print(\"Balanced Dataset Testing score:\", rf.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coverage_info1</th>\n",
       "      <th>Coverage_info2</th>\n",
       "      <th>Field_info2</th>\n",
       "      <th>Geographic_info1</th>\n",
       "      <th>Geographic_info2</th>\n",
       "      <th>Geographic_info3</th>\n",
       "      <th>Personal_info2</th>\n",
       "      <th>Personal_info4</th>\n",
       "      <th>Personal_info5</th>\n",
       "      <th>Property_info4</th>\n",
       "      <th>...</th>\n",
       "      <th>Property_info3_J</th>\n",
       "      <th>Property_info3_K</th>\n",
       "      <th>Property_info3_L</th>\n",
       "      <th>Property_info3_M</th>\n",
       "      <th>Property_info3_N</th>\n",
       "      <th>Property_info3_O</th>\n",
       "      <th>Property_info3_P</th>\n",
       "      <th>Property_info3_Q</th>\n",
       "      <th>Property_info3_R</th>\n",
       "      <th>Property_info3_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78225</th>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78226</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78227</th>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78228</th>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78229</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coverage_info1  Coverage_info2  Field_info2  Geographic_info1  \\\n",
       "78225              11              22       0.9685                 4   \n",
       "78226               7              22       0.9153                 2   \n",
       "78227              21              22       0.9566                 4   \n",
       "78228              25              22       0.9403                 2   \n",
       "78229               4              22       0.8870                18   \n",
       "\n",
       "       Geographic_info2  Geographic_info3  Personal_info2  Personal_info4  \\\n",
       "78225                19                -1              13               0   \n",
       "78226                13                -1              -1               0   \n",
       "78227                21                -1              -1               0   \n",
       "78228                 4                -1              13               0   \n",
       "78229                 4                -1              18               0   \n",
       "\n",
       "       Personal_info5  Property_info4  ...  Property_info3_J  \\\n",
       "78225             2.0               1  ...                 0   \n",
       "78226             2.0               1  ...                 0   \n",
       "78227             2.0               1  ...                 0   \n",
       "78228             2.0               0  ...                 0   \n",
       "78229             2.0               1  ...                 0   \n",
       "\n",
       "       Property_info3_K  Property_info3_L  Property_info3_M  Property_info3_N  \\\n",
       "78225                 0                 0                 0                 0   \n",
       "78226                 0                 0                 0                 0   \n",
       "78227                 0                 0                 0                 0   \n",
       "78228                 0                 0                 0                 0   \n",
       "78229                 0                 0                 0                 0   \n",
       "\n",
       "       Property_info3_O  Property_info3_P Property_info3_Q  Property_info3_R  \\\n",
       "78225                 0                 0                0                 1   \n",
       "78226                 0                 0                0                 0   \n",
       "78227                 0                 0                1                 0   \n",
       "78228                 1                 0                0                 0   \n",
       "78229                 0                 0                0                 0   \n",
       "\n",
       "       Property_info3_S  \n",
       "78225                 0  \n",
       "78226                 0  \n",
       "78227                 0  \n",
       "78228                 0  \n",
       "78229                 0  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = gb.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berier Score Loss: 0.08818342151675485\n",
      "F1 Score 0.9096060442525634\n",
      "Jaccard Score 0.834199455580302\n",
      "Mean Squared Error 0.08818342151675485\n",
      "Balanced Accuracy Score 0.9117199336116648\n",
      "Accuracy Score 0.9118165784832452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "print(\"Berier Score Loss:\", brier_score_loss(ytest, y_preds))\n",
    "print(\"F1 Score\", f1_score(ytest, y_preds))\n",
    "print(\"Jaccard Score\", jaccard_score(ytest, y_preds))\n",
    "print(\"Mean Squared Error\", mean_squared_error(ytest, y_preds))\n",
    "print(\"Balanced Accuracy Score\", balanced_accuracy_score(ytest, y_preds))\n",
    "print(\"Accuracy Score\", accuracy_score(ytest, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_csv('Solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"QuoteConversion_Flag\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('Solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
